package parse;

import java.util.*;

import jdk.nashorn.internal.ir.CaseNode;
import syms.Predefined;
import syms.Scope;
import syms.SymEntry;
import syms.SymbolTable;
import syms.Type;
import tree.ConstExp;
import tree.DeclNode;
import tree.ExpNode;
import tree.Operator;
import tree.StatementNode;

import source.ErrorHandler;
import source.Errors;
import java_cup.runtime.ComplexSymbolFactory.Location;

/**
 * class Parser - PL0 recursive descent parser. To understand how this parser
 * works read the notes on recursive descent parsing.
 * <p>
 * The syntax analyzer recognises a PL0 program according to the following
 * syntax specification using a recursive descent parser. It constructs
 * the corresponding abstract syntax tree and skeleton symbol table.
 * PL0 EBNF Grammar:
 * Program -> Block ENDOFFILE
 * Block -> { Declaration } CompoundStatement
 * Declaration -> ConstDefList | TypeDefList | VarDeclList | ProcedureDef
 * ConstDefList -> KW_CONST ConstDef { ConstDef }
 * ConstDef -> IDENTIFIER EQUALS Constant SEMICOLON
 * Constant -> NUMBER | IDENTIFIER | MINUS Constant
 * TypeDefList -> KW_TYPE TypeDef { TypeDef }
 * TypeDef -> IDENTIFIER EQUALS Type SEMICOLON
 * Type -> TypeIdentifier | SubrangeType
 * TypeIdentifier -> IDENTIFIER
 * SubrangeType -> LBRACKET Constant RANGE Constant RBRACKET
 * VarDeclList -> KW_VAR VarDecl { VarDecl }
 * VarDecl -> IDENTIFIER COLON TypeIdentifier SEMICOLON
 * ProcedureDef -> ProcedureHead EQUALS Block SEMICOLON
 * ProcedureHead -> KW_PROCEDURE IDENTIFIER LPAREN FormalParameters RPAREN
 * FormalParameters ->
 * CompoundStatement -> KW_BEGIN StatementList KW_END
 * StatementList -> Statement { SEMICOLON Statement }
 * Statement -> WhileStatement | IfStatement | CallStatement | Assignment |
 *          ReadStatement | WriteStatement | CompoundStatement
 * Assignment -> SingleAssign { BAR SingleAssign }
 * SingleAssign -> LValue ASSIGN Condition
 * WhileStatement -> KW_WHILE Condition KW_DO Statement
 * IfStatement -> KW_IF Condition KW_THEN Statement KW_ELSE Statement
 * CallStatement -> KW_CALL IDENTIFIER LPAREN ActualParameters RPAREN
 * ActualParameters ->
 * ReadStatement -> KW_READ LValue
 * WriteStatement -> KW_WRITE Exp
 * Condition -> RelCondition
 * RelCondition -> Exp [ RelOp Exp ]
 * RelOp   -> EQUALS | NEQUALS | LEQUALS | LESS | GREATER | GEQUALS
 * Exp     -> [ PLUS | MINUS ] Term   { ( PLUS | MINUS ) Term }
 * Term    -> Factor { ( TIMES | DIVIDE ) Factor }
 * Factor  -> LPAREN Condition RPAREN | NUMBER | LValue
 * LValue -> IDENTIFIER
 * <p>
 * where any constructs not defined by the above productions
 * are terminal symbols generated by the lexical analyser.
 */
public class Parser {

    //*************************** Instance Variables ************************
    /**
     * The input token stream
     */
    private TokenStream tokens;
    /**
     * The object to report errors to
     */
    private final Errors errors = ErrorHandler.getErrorHandler();

    //****************************** Constructor ****************************

    /**
     * Construct a parser with the given token stream
     *
     * @param tokens - stream of lexical tokens
     *               requires tokens != null;
     */
    public Parser(TokenStream tokens) {
        /* Set up an input token stream */
        this.tokens = tokens;
    }

    //***************************** Public Methods ****************************

    /**
     * Parse the input stream.
     *
     * @return the constructed tree but note that this may be null if
     * the parser failed to match a program.
     */
    public DeclNode.ProcedureNode parseMain() {
        DeclNode.ProcedureNode program = parseProgram(new TokenSet(Token.EOF));
        errors.flush();
        return program;
    }

    /**
     * Interface used to allow the parsers for non-terminals to
     * be written in terms of lambda expressions.
     */

    interface ParseVoid {
        void parseBody();
    }

    /**
     * Parse the non-terminal named rule, that starts with expected, in a
     * context with syntax error recovery tokens in recoverSet, using
     * the recogniser parser. These versions are for when there is no
     * result (node) to be returned by the particular parser,
     * i.e. the result type of the parser is void.
     *
     * @param rule       - the name of the non-terminal being recognised
     * @param expected   - the start set for the non-terminal
     * @param recoverSet - the syntax error recovery set
     * @param parser     - function that parses the non-terminal
     */
    private void parse(String rule, TokenSet expected, TokenSet recoverSet,
                       ParseVoid parser) {
        if (!tokens.beginRule(rule, expected, recoverSet)) {
            return;
        }
        assert tokens.isIn(expected);
        // Call the parser function that was passed as a parameter
        parser.parseBody();
        tokens.endRule(rule, recoverSet);
    }

    /**
     * A version of the previous method with a single token start set.
     */
    private void parse(String rule, Token expected, TokenSet recoverSet,
                       ParseVoid parser) {
        parse(rule, new TokenSet(expected), recoverSet, parser);
    }

    /**
     * Interface for handling error node returns from the parser
     * when the parser method matches nothing due to a syntax error.
     */
    interface ErrorReturn<Node> {
        Node errorReturn(Location loc);
    }

    /**
     * Interface used to allow the parsers for non-terminals to
     * be written in terms of lambda expressions.
     *
     * @param <Node> type of the tree node returned by the parser
     */
    interface ParseNonTerminal<Node> {
        Node parseBody();
    }

    /**
     * Class ParserMethod provides generic methods for parsing a non-terminal
     * and returning a result that is usually a tree node of the generic type Node.
     */
    class ParseMethod<Node> {
        /**
         * Provides the function to construct an error node of type Node
         */
        final ErrorReturn<Node> errorNode;

        /**
         * The constructor takes a function to construct an error node
         * of type Node
         */
        ParseMethod(ErrorReturn<Node> errorNode) {
            this.errorNode = errorNode;
        }

        /**
         * Parse the non-terminal name rule, that starts with expected,
         * in a context with syntax error recovery tokens in recoverSet,
         * using the recogniser parser.
         * These versions are for when there is a result of the generic
         * type Node to be returned by the particular parser.
         *
         * @param rule       - the name of the non-terminal being recognised
         * @param expected   - the start set for the non-terminal
         * @param recoverSet - the syntax error recovery set
         * @param parser     - function that parses the non-terminal
         * @return the abstract syntax tree node for the construct parsed
         */
        private Node parse(String rule, TokenSet expected, TokenSet recoverSet,
                           ParseNonTerminal<Node> parser) {
            if (!tokens.beginRule(rule, expected, recoverSet)) {
                return errorNode.errorReturn(tokens.getLocation());
            }
            assert tokens.isIn(expected);
            // Call the parser function that was passed as a parameter
            Node result = parser.parseBody();
            tokens.endRule(rule, recoverSet);
            return result;
        }

        /**
         * Version of the previous when the start contains just one token
         */
        private Node parse(String rule, Token expected, TokenSet recoverSet,
                           ParseNonTerminal<Node> parser) {
            return parse(rule, new TokenSet(expected), recoverSet, parser);
        }
    }

    /**
     * Methods for parsing expressions all return an ExpNode,
     * even if there is an error, in which case they'll return
     * an ExpNode.ErrorNode.
     */
    private final ParseMethod<ExpNode> exp = new ParseMethod<>(
            (Location loc) -> new ExpNode.ErrorNode(loc) );

    /**
     * Set of tokens that may start an LValue.
     */
    private final static TokenSet LVALUE_START_SET =
            new TokenSet(Token.IDENTIFIER);
    /**
     * Set of tokens that may start a Factor.
     */
    private final static TokenSet FACTOR_START_SET =
            LVALUE_START_SET.union(Token.NUMBER, Token.LPAREN);
    /**
     * Set of tokens that may start a Term.
     */
    private final static TokenSet TERM_START_SET =
            FACTOR_START_SET;
    /**
     * Set of tokens that may start an Expression.
     */
    private final static TokenSet EXP_START_SET =
            TERM_START_SET.union(Token.PLUS, Token.MINUS);
    /**
     * Set of tokens that may start a RelCondition.
     */
    private final static TokenSet REL_CONDITION_START_SET =
            EXP_START_SET;
    /**
     * Set of tokens that may start a Condition.
     */
    private final static TokenSet CONDITION_START_SET =
            REL_CONDITION_START_SET;

    //************ Operation sets for expressions ***************************
    /**
     * Set of tokens representing relational operators.
     */
    private final static TokenSet REL_OPS_SET =
            new TokenSet(Token.EQUALS, Token.NEQUALS, Token.LESS, Token.GREATER,
                    Token.LEQUALS, Token.GEQUALS);
    /**
     * Set of tokens for expression operators.
     */
    private final static TokenSet EXP_OPS_SET =
            new TokenSet(Token.PLUS, Token.MINUS);
    /**
     * Set of tokens for term operators.
     */
    private final static TokenSet TERM_OPS_SET =
            new TokenSet(Token.TIMES, Token.DIVIDE);


    /**
     * Rule: Condition -> RelCondition
     */
    private ExpNode parseCondition(TokenSet recoverSet) {
        /* Let parseRelCondition handle the syntax error recovery, for now */
        return parseRelCondition(recoverSet);
    }

    /**
     * Rule: RelCondition -> Exp [ RelOp Exp ]
     */
    private ExpNode parseRelCondition(TokenSet recoverSet) {
        return exp.parse("RelCondition", REL_CONDITION_START_SET, recoverSet,
                () -> {
                    /* The current token is in REL_CONDITION_START_SET */
                    ExpNode cond = parseExp(recoverSet.union(REL_OPS_SET));
                    if (tokens.isIn(REL_OPS_SET)) {
                        Location loc = tokens.getLocation();
                        Operator operatorCode =
                                parseRelOp(recoverSet.union(EXP_START_SET));
                        ExpNode right = parseExp(recoverSet);
                        cond = new ExpNode.BinaryNode(loc, operatorCode, cond, right);
                    }
                    return cond;
                });
    }

    /**
     * Create parse method with return type Operator, with a function
     * for syntax errors that returns the invalid operator.
     */
    private final ParseMethod<Operator> op = new ParseMethod<>(
            (Location loc) -> Operator.INVALID_OP);

    /**
     * Rule: RelOp -> EQUALS | NEQUALS | LESS | GREATER | LEQUALS | GEQUALS
     */
    private Operator parseRelOp(TokenSet recoverSet) {
        return op.parse("RelOp", REL_OPS_SET, recoverSet,
                () -> {
                    /* The current token is in REL_OPS_SET.
                     * Rather than using a cascaded if-the-else, as indicated in the
                     * recursive descent parsing notes, it is simpler to use a
                     * switch statement when all the branches have a start set that
                     * contains just one token. */
                    Operator operatorCode = Operator.INVALID_OP;
                    switch (tokens.getKind()) {
                        case EQUALS:
                            operatorCode = Operator.EQUALS_OP;
                            tokens.match(Token.EQUALS); /* cannot fail */
                            break;
                        case NEQUALS:
                            operatorCode = Operator.NEQUALS_OP;
                            tokens.match(Token.NEQUALS); /* cannot fail */
                            break;
                        case LESS:
                            operatorCode = Operator.LESS_OP;
                            tokens.match(Token.LESS); /* cannot fail */
                            break;
                        case GREATER:
                            operatorCode = Operator.GREATER_OP;
                            tokens.match(Token.GREATER); /* cannot fail */
                            break;
                        case LEQUALS:
                            operatorCode = Operator.LEQUALS_OP;
                            tokens.match(Token.LEQUALS); /* cannot fail */
                            break;
                        case GEQUALS:
                            operatorCode = Operator.GEQUALS_OP;
                            tokens.match(Token.GEQUALS); /* cannot fail */
                            break;
                        default:
                            fatal("parseRelOp");
                    }
                    return operatorCode;
                });
    }

    /**
     * Rule: Exp -> [ PLUS | MINUS ] Term { ( PLUS | MINUS ) Term }
     */
    private ExpNode parseExp(TokenSet recoverSet) {
        return exp.parse("Expression", EXP_START_SET, recoverSet,
                () -> {
                    /* The current token is in EXP_START_SET */
                    boolean haveUnaryMinus = false;
                    Location loc = tokens.getLocation();
                    if (tokens.isMatch(Token.MINUS)) {
                        haveUnaryMinus = true;
                        tokens.match(Token.MINUS); /* cannot fail */
                    } else if (tokens.isMatch(Token.PLUS)) {
                        tokens.match(Token.PLUS); /* cannot fail */
                    }
                    ExpNode exp = parseTerm(recoverSet.union(EXP_OPS_SET));
                    if (haveUnaryMinus) {
                        exp = new ExpNode.UnaryNode(loc, Operator.NEG_OP, exp);
                    }
                    while (tokens.isIn(EXP_OPS_SET)) {
                        Operator operatorCode = Operator.INVALID_OP;
                        loc = tokens.getLocation();
                        if (tokens.isMatch(Token.MINUS)) {
                            operatorCode = Operator.SUB_OP;
                            tokens.match(Token.MINUS); /* cannot fail */
                        } else if (tokens.isMatch(Token.PLUS)) {
                            operatorCode = Operator.ADD_OP;
                            tokens.match(Token.PLUS); /* cannot fail */
                        } else {
                            fatal("parseExp");
                        }
                        ExpNode right = parseTerm(recoverSet.union(EXP_OPS_SET));
                        exp = new ExpNode.BinaryNode(loc, operatorCode, exp, right);
                    }
                    return exp;
                });
    }

    /**
     * Rule: Term  -> Factor { ( TIMES | DIVIDE ) Factor }
     */
    private ExpNode parseTerm(TokenSet recoverSet) {
        return exp.parse("Term", TERM_START_SET, recoverSet,
                () -> {
                    /* The current token is in TERM_START_SET */
                    ExpNode term = parseFactor(recoverSet.union(TERM_OPS_SET));
                    while (tokens.isIn(TERM_OPS_SET)) {
                        Operator operatorCode = Operator.INVALID_OP;
                        Location loc = tokens.getLocation();
                        if (tokens.isMatch(Token.TIMES)) {
                            operatorCode = Operator.MUL_OP;
                            tokens.match(Token.TIMES); /* cannot fail */
                        } else if (tokens.isMatch(Token.DIVIDE)) {
                            operatorCode = Operator.DIV_OP;
                            tokens.match(Token.DIVIDE); /* cannot fail */
                        } else {
                            fatal("parseTerm");
                        }
                        ExpNode right = parseFactor(recoverSet.union(TERM_OPS_SET));
                        term = new ExpNode.BinaryNode(loc, operatorCode, term, right);
                    }
                    return term;
                });
    }

    /**
     * Rule: Factor -> LPAREN Condition RPAREN | NUMBER | LValue
     */
    private ExpNode parseFactor(TokenSet recoverSet) {
        return exp.parse("Factor", FACTOR_START_SET, recoverSet,
                () -> {
                    /* The current token is in FACTOR_START_SET */
                    ExpNode result = null;
                    if (tokens.isMatch(Token.IDENTIFIER)) {
                        result = parseLValue(recoverSet);
                    } else if (tokens.isMatch(Token.NUMBER)) {
                        result = new ExpNode.ConstNode(tokens.getLocation(),
                                Predefined.INTEGER_TYPE, tokens.getIntValue());
                        tokens.match(Token.NUMBER); /* cannot fail */
                    } else if (tokens.isMatch(Token.LPAREN)) {
                        tokens.match(Token.LPAREN); /* cannot fail */
                        result = parseCondition(recoverSet.union(Token.RPAREN));
                        tokens.match(Token.RPAREN, recoverSet);
                    } else {
                        fatal("parseFactor");
                    }
                    return result;
                });
    }

    /**
     * Rule: LValue -> IDENTIFIER
     */
    private ExpNode parseLValue(TokenSet recoverSet) {
        return exp.parse("LValue", LVALUE_START_SET, recoverSet,
                () -> {
                    /* The current token is in LVALUE_START_SET */
                    ExpNode result =
                            new ExpNode.IdentifierNode(tokens.getLocation(),
                                    tokens.getName());
                    tokens.match(Token.IDENTIFIER); /* cannot fail */
                    return result;
                });
    }

    /**
     * Methods for parsing statements all return a StatementNode,
     * even in the case where there is an error, in which case they
     * return a StatementNode.ErrorNode.
     */
    private final ParseMethod<StatementNode> stmt = new ParseMethod<>(
            (Location loc) -> new StatementNode.ErrorNode(loc) );

    /**
     * Set of tokens that may start a Statement.
     */
    private final static TokenSet STATEMENT_START_SET =
            LVALUE_START_SET.union(Token.KW_WHILE, Token.KW_IF,
                    Token.KW_READ, Token.KW_WRITE,
                    Token.KW_CALL, Token.KW_BEGIN, Token.KW_SKIP, Token.KW_CASE);

    /**
     * Rule: CompoundStatement -> BEGIN StatementList END
     */
    private StatementNode parseCompoundStatement(TokenSet recoverSet) {
        return stmt.parse("Compound Statement", Token.KW_BEGIN, recoverSet,
                () -> {
                    /* The current token is KW_BEGIN */
                    tokens.match(Token.KW_BEGIN);
                    StatementNode result =
                            parseStatementList(recoverSet.union(Token.KW_END));
                    tokens.match(Token.KW_END, recoverSet);
                    return result;
                });
    }

    /**
     * Rule: SkipStatement -> KW_SKIP
     */
    private StatementNode parseSkipStatement(TokenSet recoverSet) {
        return stmt.parse("Skip Statement", Token.KW_SKIP, recoverSet,
                () -> {
                    /* The current token is KW_SKIP */
                    tokens.match(Token.KW_SKIP);
                    Location loc = tokens.getLocation();
                    StatementNode result = new StatementNode.SkipNode(loc);
                    return result;
                });
    }

    /**
     * Rule: CaseStatement -> KW_CASE Condition KW_OF { CaseBranch } [ KW_DEFAULT StatementList ] KW_END
     */
    private StatementNode parseCaseStatement(TokenSet recoverSet) {
        return stmt.parse("Case Statement", Token.KW_CASE, recoverSet,
                () -> {
                    StatementNode defaultCase = null; // might not be needed
                    Location loc = tokens.getLocation();

                    tokens.match(Token.KW_CASE);
                    ExpNode caseValue = parseCondition(recoverSet.union(Token.KW_OF));
                    tokens.match(Token.KW_OF);

                    // Initialize result to an empty list of case statements
                    List<StatementNode> cases = new LinkedList<>();
                    StatementNode s = parseCaseBranch(recoverSet);
                    cases.add(s);
                    while (tokens.isMatch(Token.KW_WHEN)) {
                        s = parseCaseBranch(recoverSet);
                        cases.add(s);
                    }

                    // Parse default if it exists
                    if (tokens.isMatch(Token.KW_DEFAULT)) {
                        tokens.match(Token.KW_DEFAULT, STATEMENT_START_SET);
                        defaultCase = parseStatementList(recoverSet);
                    }

                    // parse KW_END
                    tokens.match(Token.KW_END, recoverSet);
                    return new StatementNode.CaseNode(loc, caseValue, cases, defaultCase);
                });
    }

    /**
     * CaseBranch -> KW_WHEN Constant COLON StatementList
     */
    private StatementNode parseCaseBranch(TokenSet recoverSet) {
        return stmt.parse("Case Branch", Token.KW_WHEN, recoverSet,
                () -> {
                    /* The current token is KW_WHEN */
                    tokens.match(Token.KW_WHEN); // Cannot fail
                    Location loc = tokens.getLocation();
                    ConstExp c = parseConstant(recoverSet.union(STATEMENT_START_SET));
                    tokens.match(Token.COLON, STATEMENT_START_SET);
                    StatementNode result = parseStatementList(recoverSet);
                    return new StatementNode.CaseBranchNode(loc, c, result);
                });
    }

    /**
     * Rule: StatementList -> Statement { SEMICOLON Statement }
     */
    private StatementNode parseStatementList(TokenSet recoverSet) {
        return stmt.parse("Statement List", STATEMENT_START_SET, recoverSet,
                () -> {
                    // The current token is in STATEMENT_START_SET
                    Location loc = tokens.getLocation();
                    // Initialize result to an empty list of statements
                    List<StatementNode> stmts = new LinkedList<>();
                    StatementNode s = parseStatement(recoverSet.union(Token.SEMICOLON));
                    stmts.add(s);
                    while (tokens.isMatch(Token.SEMICOLON)) {
                        tokens.match(Token.SEMICOLON);
                        s = parseStatement(recoverSet.union(Token.SEMICOLON));
                        stmts.add(s);
                    }
                    return new StatementNode.ListNode(loc, stmts);
                });
    }

    /**
     * Rule: Statement -> Assignment | WhileStatement | IfStatement
     * | ReadStatement | WriteStatement | CallStatement
     * | CompoundStatement
     */
    private StatementNode parseStatement(TokenSet recoverSet) {
        return stmt.parse("Statement", STATEMENT_START_SET, recoverSet,
                () -> {
                    /* The current token is in STATEMENT_START_SET.
                     * Instead of using a cascaded if-the-else, as indicated in
                     * the recursive descent parsing notes, a simpler approach
                     * of using a switch statement can be used because the
                     * start set of every alternative contains just one token. */
                    switch (tokens.getKind()) {
                        case IDENTIFIER:
                            return parseAssignment(recoverSet);
                        case KW_WHILE:
                            return parseWhileStatement(recoverSet);
                        case KW_IF:
                            return parseIfStatement(recoverSet);
                        case KW_READ:
                            return parseReadStatement(recoverSet);
                        case KW_WRITE:
                            return parseWriteStatement(recoverSet);
                        case KW_CALL:
                            return parseCallStatement(recoverSet);
                        case KW_BEGIN:
                            return parseCompoundStatement(recoverSet);
                        case KW_SKIP:
                            return parseSkipStatement(recoverSet);
//                        case KW_CASE: //TODO: Take out/put in to pass the tests lol
//                            return parseCaseStatement(recoverSet);
                        default:
                            fatal("parseStatement");
                            // To keep the Java compiler happy - can't reach here
                            return new StatementNode.ErrorNode(tokens.getLocation());
                    }
                });
    }

    private final ParseMethod<StatementNode.SingleAssignmentNode> singleAssign =
            new ParseMethod<>(
                    (Location loc) -> new StatementNode.SingleAssignmentNode(loc,
                            new ExpNode.ErrorNode(loc), new ExpNode.ErrorNode(loc)));

    /**
     * Rule: SingleAssign -> LValue ASSIGN Condition
     */
    private StatementNode.SingleAssignmentNode parseSingleAssignment(TokenSet recoverSet) {
        return singleAssign.parse("Assignment", LVALUE_START_SET, recoverSet,
                () -> {
                    /* The current token is in LVALUE_START_SET.
                     * Non-standard recovery set includes EQUALS because a
                     * common syntax error is to use EQUALS instead of ASSIGN.
                     */
                    Location loc = tokens.getLocation();
                    ExpNode left = parseLValue(
                            recoverSet.union(Token.ASSIGN, Token.EQUALS));
                    tokens.match(Token.ASSIGN, CONDITION_START_SET);
                    ExpNode right = parseCondition(recoverSet);
                    return new StatementNode.SingleAssignmentNode(loc, left, right);
                });
    }

    private final ParseMethod<StatementNode> assign =
            new ParseMethod<>(
                    (Location loc) -> new StatementNode.ErrorNode(loc));

    /**
     * Rule: Assignment ->  SingleAssign { BAR SingleAssign }
     */
    private StatementNode parseAssignment(TokenSet recoverSet) {
        return assign.parse("Assignment", LVALUE_START_SET, recoverSet,
                () -> {
                    Location loc = tokens.getLocation();
                    List<StatementNode.SingleAssignmentNode> assignments = new LinkedList<>();
                    assignments.add(parseSingleAssignment(recoverSet));

                    while(tokens.isMatch(Token.BAR)) {
                        tokens.match(Token.BAR);
                        assignments.add(parseSingleAssignment(recoverSet));
                    }
                    return new StatementNode.AssignmentNode(loc, assignments);
                });
    }

    /**
     * Rule: WhileStatement -> KW_WHILE Condition KW_DO Statement
     */
    private StatementNode parseWhileStatement(TokenSet recoverSet) {
        return stmt.parse("While Statement", Token.KW_WHILE, recoverSet,
                () -> {
                    /* The current token is KW_WHILE */
                    tokens.match(Token.KW_WHILE); /* cannot fail */
                    Location loc = tokens.getLocation();
                    ExpNode cond = parseCondition(recoverSet.union(Token.KW_DO));
                    tokens.match(Token.KW_DO, STATEMENT_START_SET);
                    StatementNode statement = parseStatement(recoverSet);
                    return new StatementNode.WhileNode(loc, cond, statement);
                });
    }

    /**
     * Rule: IfStatement -> KW_IF Condition KW_THEN Statement KW_ELSE Statement
     */
    private StatementNode parseIfStatement(TokenSet recoverSet) {
        return stmt.parse("If Statement", Token.KW_IF, recoverSet,
                () -> {
                    /* The current token is KW_IF */
                    tokens.match(Token.KW_IF); /* cannot fail */
                    Location loc = tokens.getLocation();
                    ExpNode cond = parseCondition(recoverSet.union(Token.KW_THEN));
                    tokens.match(Token.KW_THEN, STATEMENT_START_SET);
                    StatementNode thenClause =
                            parseStatement(recoverSet.union(Token.KW_ELSE));
                    tokens.match(Token.KW_ELSE, STATEMENT_START_SET);
                    StatementNode elseClause = parseStatement(recoverSet);
                    return new StatementNode.IfNode(loc, cond, thenClause, elseClause);
                });
    }

    /**
     * Rule: ReadStatement -> KW_READ LValue
     */
    private StatementNode parseReadStatement(TokenSet recoverSet) {
        return stmt.parse("Read Statement", Token.KW_READ, recoverSet,
                () -> {
                    /* The current token is KW_READ */
                    tokens.match(Token.KW_READ); /* cannot fail */
                    Location loc = tokens.getLocation();
                    ExpNode lVal = parseLValue(recoverSet);
                    return new StatementNode.ReadNode(loc, lVal);
                });
    }

    /**
     * Rule: WriteStatement -> KW_WRITE Exp
     */
    private StatementNode parseWriteStatement(TokenSet recoverSet) {
        return stmt.parse("Write Statement", Token.KW_WRITE, recoverSet,
                () -> {
                    /* The current token is KW_WRITE */
                    tokens.match(Token.KW_WRITE); /* cannot fail */
                    Location loc = tokens.getLocation();
                    ExpNode exp = parseExp(recoverSet);
                    return new StatementNode.WriteNode(loc, exp);
                });
    }

    /**
     * Rule: CallStatement -> KW_CALL IDENTIFIER LPAREN RPAREN
     */
    private StatementNode parseCallStatement(TokenSet recoverSet) {
        return stmt.parse("Call Statement", Token.KW_CALL, recoverSet,
                () -> {
                    /* The current token is KW_CALL */
                    tokens.match(Token.KW_CALL); /* cannot fail */
                    Location loc = tokens.getLocation();
                    String procId;
                    if (tokens.isMatch(Token.IDENTIFIER)) {
                        procId = tokens.getName();
                    } else {
                        procId = "<no_id>";
                    }
                    tokens.match(Token.IDENTIFIER, Token.LPAREN);
                    tokens.match(Token.LPAREN, Token.RPAREN);
                    // Empty actual parameter list currently
                    tokens.match(Token.RPAREN, recoverSet);
                    return new StatementNode.CallNode(loc, procId
                    );
                });
    }

    /**
     * Set of tokens that may start a Declaration.
     */
    private final static TokenSet DECLARATION_START_SET =
            new TokenSet(Token.KW_CONST, Token.KW_TYPE, Token.KW_VAR,
                    Token.KW_PROCEDURE);
    /**
     * Set of tokens that may start a Block.
     */
    private final static TokenSet BLOCK_START_SET =
            DECLARATION_START_SET.union(Token.KW_BEGIN);
    /**
     * Set of tokens that may start a Constant.
     */
    private final static TokenSet CONSTANT_START_SET =
            new TokenSet(Token.IDENTIFIER, Token.NUMBER, Token.MINUS);
    /**
     * Set of tokens that may start a Type.
     */
    private final static TokenSet TYPE_START_SET =
            new TokenSet(Token.IDENTIFIER, Token.LBRACKET);

    /**
     * The current symbol table scope
     */
    private Scope currentScope;

    /**
     * Method for parsing top-level program.
     */
    private final ParseMethod<DeclNode.ProcedureNode> proc =
            new ParseMethod<>( (Location loc) -> null );

    /**
     * RULE: Program -> Block ENDOFFILE
     */
    private DeclNode.ProcedureNode parseProgram(TokenSet recoverSet) {
        return proc.parse("Program", BLOCK_START_SET, recoverSet,
                () -> {
                    /* The current token is in BLOCK_START_SET.
                     * Set up a symbol table.
                     * The initial value includes the predefined scope.
                     */
                    SymbolTable symbolTable = new SymbolTable();
                    currentScope = symbolTable.getPredefinedScope();
                    SymEntry.ProcedureEntry proc =
                            currentScope.addProcedure("<main>", tokens.getLocation());
                    if (proc == null) {
                        errors.fatal("Could not add main program to symbol table",
                                tokens.getLocation());
                        return null; // Unreachable but keep Java compiler happy
                    }
                    // Add a new symbol table scope for the main program
                    currentScope = currentScope.newScope(proc);
                    StatementNode.BlockNode block = parseBlock(recoverSet);
                    // Exit the scope for the main program
                    currentScope = currentScope.getParent();
                    /* We can't use match for ENDOFFILE
                     * because there is nothing following end of file
                     * but the implicit call on endRule only allows an ENDOFFILE
                     * to follow the main program. */
                    return new DeclNode.ProcedureNode(proc, block);
                });
    }

    /**
     * Method for parsing a block.
     */
    private final ParseMethod<StatementNode.BlockNode> block =
            new ParseMethod<>(
                    (Location loc) -> new StatementNode.BlockNode(tokens.getLocation(),
                            new DeclNode.DeclListNode(),
                            new StatementNode.ErrorNode(tokens.getLocation()),
                            currentScope));

    /**
     * RULE: Block -> { Declaration } CompoundStatement
     */
    private StatementNode.BlockNode parseBlock(TokenSet recoverSet) {
        return block.parse("Block", BLOCK_START_SET, recoverSet,
                () -> {
                    /* The current token is in BLOCK_START_SET */
                    DeclNode.DeclListNode procedures = new DeclNode.DeclListNode();
                    while (tokens.isIn(DECLARATION_START_SET)) {
                        procedures = parseDeclaration(procedures,
                                recoverSet.union(BLOCK_START_SET));
                    }
                    StatementNode statements = parseCompoundStatement(recoverSet);
                    return new StatementNode.BlockNode(statements.getLocation(),
                            procedures, statements, currentScope);
                });
    }

    /**
     * Method for parsing a declaration list.
     */
    private final ParseMethod<DeclNode.DeclListNode> declList =
            new ParseMethod<>( (Location loc) -> null );

    /**
     * RULE:
     * Declaration -> ConstDefList | TypeDefList | VarDeclList | ProcedureDef
     */
    private DeclNode.DeclListNode parseDeclaration(
            DeclNode.DeclListNode procedures, TokenSet recoverSet) {
        return declList.parse("Declaration", DECLARATION_START_SET, recoverSet,
                () -> {
                    /* The current token is in DECLARATION_START_SET */
                    if (tokens.isMatch(Token.KW_CONST)) {
                        parseConstDefList(recoverSet);
                    } else if (tokens.isMatch(Token.KW_TYPE)) {
                        parseTypeDefList(recoverSet);
                    } else if (tokens.isMatch(Token.KW_VAR)) {
                        parseVarDeclList(recoverSet);
                    } else if (tokens.isMatch(Token.KW_PROCEDURE)) {
                        DeclNode.ProcedureNode proc = parseProcedureDef(recoverSet);
                        procedures.addDeclaration(proc);
                    } else { // cannot get here
                        fatal("parseDeclaration");
                    }
                    return procedures;
                });
    }

    /**
     * Rule: ConstDefList -> KW_CONST ConstDef { ConstDef }
     */
    private void parseConstDefList(TokenSet recoverSet) {
        parse("Constant Definition List", Token.KW_CONST, recoverSet,
                () -> {
                    /* The current token is KW_CONST */
                    tokens.match(Token.KW_CONST); // cannot fail
                    do {
                        parseConstDef(recoverSet.union(Token.IDENTIFIER));
                    } while (tokens.isMatch(Token.IDENTIFIER));
                });
    }

    /**
     * Rule: ConstDef -> IDENTIFIER EQUALS Constant SEMICOLON
     */
    private void parseConstDef(TokenSet recoverSet) {
        parse("Constant Definition", Token.IDENTIFIER, recoverSet,
                () -> {
                    /* The current token is IDENTIFIER */
                    String name = tokens.getName();
                    Location loc = tokens.getLocation();
                    tokens.match(Token.IDENTIFIER);    /* cannot fail */
                    tokens.match(Token.EQUALS, CONSTANT_START_SET);
                    ConstExp tree =
                            parseConstant(recoverSet.union(Token.SEMICOLON));
                    if (currentScope.addConstant(name, loc, tree) == null) {
                        errors.error("Constant identifier " + name +
                                " already declared in this scope", loc);
                    }
                    tokens.match(Token.SEMICOLON, recoverSet);
                });
    }

    /**
     * Method for parsing a constant expression.
     */
    private final ParseMethod<ConstExp> constExp =
            new ParseMethod<>(
                    (Location loc) -> new ConstExp.ErrorNode(tokens.getLocation()));

    /**
     * Rule: Constant -> NUMBER | IDENTIFIER | MINUS Constant
     */
    private ConstExp parseConstant(TokenSet recoverSet) {
        return constExp.parse("Constant", CONSTANT_START_SET, recoverSet,
                () -> {
                    /* The current token is in CONSTANT_START_SET */
                    ConstExp tree = null;
                    if (tokens.isMatch(Token.NUMBER)) {
                        tree = new ConstExp.NumberNode(tokens.getLocation(),
                                Predefined.INTEGER_TYPE,
                                tokens.getIntValue());
                        tokens.match(Token.NUMBER); /* cannot fail */
                    } else if (tokens.isMatch(Token.IDENTIFIER)) {
                        tree = new ConstExp.ConstIdNode(tokens.getLocation(),
                                tokens.getName(), currentScope);
                        tokens.match(Token.IDENTIFIER); /* cannot fail */
                    } else if (tokens.isMatch(Token.MINUS)) {
                        Location loc = tokens.getLocation();
                        tokens.match(Token.MINUS); /* cannot fail */
                        tree = parseConstant(recoverSet);
                        tree = new ConstExp.NegateNode(loc, tree);
                    } else {
                        fatal("parseConstant");
                        // unreachable
                    }
                    return tree;
                });
    }

    /**
     * Rule: TypeDefList -> KW_TYPE TypeDef { TypeDef }
     */
    private void parseTypeDefList(TokenSet recoverSet) {
        parse("Type Definition List", Token.KW_TYPE, recoverSet,
                () -> {
                    /* The current token is KW_TYPE */
                    tokens.match(Token.KW_TYPE);  // cannot fail
                    do {
                        parseTypeDef(recoverSet.union(Token.IDENTIFIER));
                    } while (tokens.isMatch(Token.IDENTIFIER));
                });
    }

    /**
     * Rule: TypeDef -> IDENTIFIER EQUALS Type SEMICOLON
     */
    private void parseTypeDef(TokenSet recoverSet) {
        parse("Type Definition", Token.IDENTIFIER, recoverSet,
                () -> {
                    /* The current token is IDENTIFIER */
                    String name = tokens.getName();
                    Location loc = tokens.getLocation();
                    tokens.match(Token.IDENTIFIER);        /* cannot fail */
                    tokens.match(Token.EQUALS, TYPE_START_SET);
                    Type type = parseType(recoverSet.union(Token.SEMICOLON));
                    if (currentScope.addType(name, loc, type) == null) {
                        errors.error("Type identifier " + name +
                                " already declared in this scope", loc);
                    }
                    tokens.match(Token.SEMICOLON, recoverSet);
                });
    }

    /**
     * Method for parsing a type.
     */
    private final ParseMethod<Type> type =
            new ParseMethod<>( (Location loc) -> Type.ERROR_TYPE );

    /**
     * Rule: Type -> TypeIdentifier | SubrangeType
     */
    private Type parseType(TokenSet recoverSet) {
        return type.parse("Type", TYPE_START_SET, recoverSet,
                () -> {
                    /* The current token is in TYPE_START_SET */
                    Type type = null;
                    if (tokens.isMatch(Token.IDENTIFIER)) {
                        type = parseTypeIdentifier(recoverSet);
                    } else if (tokens.isMatch(Token.LBRACKET)) {
                        type = parseSubrangeType(recoverSet);
                    } else {
                        fatal("parseType");
                    }
                    return type;
                });
    }

    /**
     * Rule: SubrangeType -> LBRACKET Constant RANGE Constant RBRACKET
     */
    private Type parseSubrangeType(TokenSet recoverSet) {
        return type.parse("Subrange Type", Token.LBRACKET, recoverSet,
                () -> {
                    /* The current token is LBRACKET */
                    Location loc = tokens.getLocation();
                    tokens.match(Token.LBRACKET); /* cannot fail */
                    ConstExp lower = parseConstant(recoverSet.union(Token.RANGE));
                    tokens.match(Token.RANGE, CONSTANT_START_SET);
                    ConstExp upper = parseConstant(recoverSet.union(Token.RBRACKET));
                    tokens.match(Token.RBRACKET, recoverSet);
                    return new Type.SubrangeType(loc, lower, upper);
                });
    }

    /**
     * Rule: TypeIdentifier -> IDENTIFIER
     */
    private Type parseTypeIdentifier(TokenSet recoverSet) {
        return type.parse("Type Identifier", Token.IDENTIFIER, recoverSet,
                () -> {
                    /* The current token is IDENTIFIER */
                    String name = tokens.getName();
                    Location loc = tokens.getLocation();
                    tokens.match(Token.IDENTIFIER);    /* cannot fail */
                    return new Type.IdRefType(loc, name, currentScope);
                });
    }

    /**
     * Rule: VarDeclList -> KW_VAR VarDecl { VarDecl }
     */
    private void parseVarDeclList(TokenSet recoverSet) {
        parse("Variable Declaration List", Token.KW_VAR, recoverSet,
                () -> {
                    /* The current token is KW_VAR */
                    tokens.match(Token.KW_VAR); /* cannot fail */
                    do {
                        parseVarDecl(recoverSet.union(Token.IDENTIFIER));
                    } while (tokens.isMatch(Token.IDENTIFIER));
                });
    }

    /**
     * Rule: VarDecl -> IDENTIFIER COLON TypeIdentifier SEMICOLON
     */
    private void parseVarDecl(TokenSet recoverSet) {
        parse("Variable Declaration", Token.IDENTIFIER, recoverSet,
                () -> {
                    /* The current token is IDENTIFIER */
                    String name = tokens.getName();
                    Location loc = tokens.getLocation();
                    tokens.match(Token.IDENTIFIER);     /* cannot fail */
                    tokens.match(Token.COLON, TYPE_START_SET);
                    Type type = parseTypeIdentifier(recoverSet.union(Token.SEMICOLON));
                    // The type of a variable must be a reference type
                    //if (currentScope.addVariable(name, loc,
                    //        new Type.ReferenceType(type)) == null) {
                    // Larissa had to change this code because of update to addVariable
                    if (currentScope.addVariable(name, loc, type) == null) {
                        errors.error("Variable identifier " + name +
                                " already declared in this scope", loc);
                    }
                    tokens.match(Token.SEMICOLON, recoverSet);
                });
    }

    /**
     * Rule: ProcedureDef -> ProcedureHead EQUALS Block SEMICOLON
     */
    private DeclNode.ProcedureNode parseProcedureDef(TokenSet recoverSet) {
        return proc.parse("Procedure Definition", Token.KW_PROCEDURE, recoverSet,
                () -> {
                    /* The current token is KW_PROCEDURE
                     * A common syntax error is to forget the EQUALS, hence the
                     * recovery set contains tokens that can follow the EQUALS,
                     * i.e. start a Block.
                     * In general the recovery set can include tokens appearing
                     * later in the production than immediately following tokens.
                     */
                    SymEntry.ProcedureEntry procEntry = parseProcedureHead(
                            recoverSet.union(Token.EQUALS).union(BLOCK_START_SET));
                    // Add a new scope for the procedure
                    currentScope = currentScope.newScope(procEntry);
                    tokens.match(Token.EQUALS, BLOCK_START_SET);
                    StatementNode.BlockNode block =
                            parseBlock(recoverSet.union(Token.SEMICOLON));
                    // Exit the scope for the procedure
                    currentScope = currentScope.getParent();
                    tokens.match(Token.SEMICOLON, recoverSet);
                    return new DeclNode.ProcedureNode(procEntry, block);
                });
    }

    /**
     * Method for parsing a procedure entry header.
     */
    private final ParseMethod<SymEntry.ProcedureEntry> procEntry =
            new ParseMethod<>( (Location loc) -> null );

    /**
     * Rule: ProcedureHead -> KW_PROCEDURE IDENTIFIER LPAREN RPAREN
     */
    private SymEntry.ProcedureEntry parseProcedureHead(TokenSet recoverSet) {
        return procEntry.parse("Procedure Header", Token.KW_PROCEDURE, recoverSet,
                () -> {
                    /* The current token is KW_PROCEDURE */
                    SymEntry.ProcedureEntry procEntry;
                    tokens.match(Token.KW_PROCEDURE);
                    if (tokens.isMatch(Token.IDENTIFIER)) {
                        procEntry = currentScope.addProcedure(tokens.getName(),
                                tokens.getLocation());
                        if (procEntry == null) {
                            errors.error("Procedure identifier " + tokens.getName() +
                                            " already declared in this scope",
                                    tokens.getLocation());
                            // Construct a dummy entry but do not add to scope
                            procEntry = new SymEntry.ProcedureEntry(tokens.getName(),
                                    tokens.getLocation());
                            procEntry.setScope(currentScope);

                        }
                    } else {
                        // Construct a dummy procedure entry but do not add to scope
                        procEntry = new SymEntry.ProcedureEntry("<undefined>",
                                tokens.getLocation());
                        procEntry.setScope(currentScope);
                    }
                    tokens.match(Token.IDENTIFIER, Token.LPAREN);
                    tokens.match(Token.LPAREN, Token.RPAREN);
                    // Empty formal parameter list currently
                    tokens.match(Token.RPAREN, recoverSet);
                    return procEntry;
                });
    }
    //******************* Private convenience Methods ************************

    /**
     * Signal a fatal error at the current token location
     */
    private void fatal(String m) {
        errors.fatal("Unreachable branch reached in " + m, tokens.getLocation());
    }
}
